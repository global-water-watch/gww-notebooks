{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef15a661",
   "metadata": {
    "id": "ef15a661"
   },
   "source": [
    "## Analyzing Cape Town's day zero with Global Water Watch's API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c15d1",
   "metadata": {
    "id": "9b3c15d1"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/global-water-watch/gww-notebooks/blob/main/01_API_storage_anomalies_Cape_Town.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e604f",
   "metadata": {
    "id": "e50e604f"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5704139e",
   "metadata": {
    "id": "5704139e"
   },
   "source": [
    "In this notebook, we'll go over a number of examples how to request data from Global Water Watch (GWW)'s API. We will reproduce some of the research done in [this](https://www.nature.com/articles/s41598-022-17074-6) paper. It presents an analysis of dry conditions around Cape Town. You can download this notebook, reproduce the results and of course adapt it for your environment. Let's first install a few dependencies we'll need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49069f4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49069f4e",
    "outputId": "0cf31678-79e3-47f6-f029-158511870d11"
   },
   "outputs": [],
   "source": [
    "!pip install geopandas\n",
    "!pip install cartopy\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07440d71",
   "metadata": {
    "id": "07440d71"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import cartopy\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import cartopy.crs as ccrs\n",
    "import datetime\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from scipy import stats\n",
    "from shapely.geometry import shape, box, mapping\n",
    "\n",
    "base_url = \"https://api.globalwaterwatch.earth\"\n",
    "start = datetime.datetime(2021, 1, 1)\n",
    "stop = datetime.datetime(2022, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40ea0a",
   "metadata": {
    "id": "1c40ea0a"
   },
   "source": [
    "### Helper functions\n",
    "First we define a set of functions that we can later use to do requests on the API, massage data into a form that can be used more easily, like pandas or geopandas `DataFrame`, or plot the data. Load in the functions, and we'll use them later on. The documentation on the different API calls can be found [here](https://api.globalwaterwatch.earth/docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdeccd8",
   "metadata": {
    "id": "1cdeccd8"
   },
   "outputs": [],
   "source": [
    "def to_geopandas(data):\n",
    "    \"\"\"\n",
    "    Ingests list of reservoirs and converts into a geopandas GeoDataFrame for further analyses\n",
    "    \n",
    "    \"\"\"\n",
    "    gdf = gpd.GeoDataFrame.from_features(data, crs=4326)\n",
    "    # reserovir ids are not in the feature itself, add explicitly\n",
    "    reservoir_ids = [int(f[\"id\"]) for f in data[\"features\"]]\n",
    "    gdf[\"id\"] = reservoir_ids\n",
    "\n",
    "#     geoms = [shape(f[\"geometry\"]) for f in data]\n",
    "#     props = [{**f[\"properties\"], **{\"id\": f[\"id\"]}} for f in data]\n",
    "    return gdf\n",
    "#     return gpd.GeoDataFrame(props, geometry=geoms, crs=4326)\n",
    "\n",
    "def get_reservoirs(skip=1, limit=5, base_url=base_url):\n",
    "    \"\"\"\n",
    "    Gets reservoirs from API. Return dict with IDs.\n",
    "    \n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/reservoir\"\n",
    "    params = {\n",
    "        \"skip\": skip,\n",
    "        \"limit\": limit,\n",
    "    }\n",
    "    return requests.get(url, params=params)\n",
    "\n",
    "\n",
    "def get_reservoir(reservoir_id):\n",
    "    \"\"\"\n",
    "    Get reservoir (geometry and props) by ID\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/reservoir/{reservoir_id}\"\n",
    "    return requests.get(url)\n",
    "    \n",
    "\n",
    "def get_reservoirs_by_geom(geom, base_url=base_url):\n",
    "    \"\"\"\n",
    "    Gets reservoirs from API. Return dict with IDs.\n",
    "    \n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/reservoir/geometry\"\n",
    "    # do post request to end point with the serialized geometry as post data\n",
    "    return requests.post(url, data=geom)\n",
    "\n",
    "\n",
    "def get_reservoir_ts(reservoir_id, start=start, stop=stop):\n",
    "    \"\"\"\n",
    "    Get time series data for reservoir with given ID\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/reservoir/{reservoir_id}/ts\"\n",
    "    params = {\n",
    "        \"start\": start.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        \"stop\": stop.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    }\n",
    "    return requests.get(url, params=params)\n",
    "    \n",
    "    \n",
    "def plot_features_map(feats, ax=None, figsize=(20, 13), tiles=None, zoom_level=1, tiles_kwargs={}, **kwargs):\n",
    "    \"\"\"\n",
    "    add a set of features to a GeoAxes map\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=figsize)\n",
    "        if tiles is not None:\n",
    "            tiler = getattr(cimgt, tiles)(**tiles_kwargs)\n",
    "            crs = tiler.crs\n",
    "        else:\n",
    "            crs = ccrs.PlateCarree()\n",
    "        # make point collection\n",
    "        ax = plt.subplot(projection=crs)\n",
    "        if tiles is not None:\n",
    "            ax.add_image(tiler, zoom_level, zorder=1)\n",
    "            feats.to_crs(3857).plot(ax=ax, zorder=2, **kwargs)\n",
    "        else:\n",
    "            feats.plot(ax=ax, **kwargs)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ba72e",
   "metadata": {
    "id": "bd9ba72e"
   },
   "source": [
    "### Get some reservoirs and properties\n",
    "The first functionality we show is a simple query on the order of IDs of reservoirs. These IDs are typical for global water watch. With options for `skip` and `limit` we can ask for reservoirs in a particular ID range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811ad34",
   "metadata": {
    "id": "4811ad34"
   },
   "outputs": [],
   "source": [
    "r = get_reservoirs(skip=50, limit=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457a0b9",
   "metadata": {
    "id": "8457a0b9"
   },
   "source": [
    "Basically we just requested to skip the first 50 reservoirs in the database, and then retrieve the 50 after those. Let's have a look at the raw response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739a3ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8739a3ab",
    "outputId": "f41a9fa3-8df6-44b6-bfe4-ed9e1fe7b68b"
   },
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1f826",
   "metadata": {
    "id": "70a1f826"
   },
   "source": [
    "We now have the response of our query in `r` and can now retrieve the data in json format. That's not very convenient as we can't easily analyze the data. So we wrote a convenience function to turn the json data into a geographically aware `geopandas.GeoDataFrame`. This makes it easier to use the data in a geospatial manner. Check out the function in the cell above, that you already loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd376aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r.json()\n",
    "gdf = gpd.GeoDataFrame.from_features(data, crs=4326)\n",
    "gdf = to_geopandas(data)\n",
    "gdf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8bbb5",
   "metadata": {
    "id": "2ec8bbb5"
   },
   "source": [
    "It looks like we have something to plot now. We also wrote a function that plots the data within a geographical map. Since the reservoirs are distributed over the world, we only show the centroids below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b557a42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 827
    },
    "id": "2b557a42",
    "outputId": "95bb0f2f-fed1-4c08-e5bb-effc7336c5b7"
   },
   "outputs": [],
   "source": [
    "plot_features_map(gdf.centroid, tiles=\"OSM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be3f0cd",
   "metadata": {
    "id": "5be3f0cd"
   },
   "source": [
    "### Reservoirs in a certain bounding box\n",
    "Interesting, but let's assume we would be interested to have data around Cape Town to investigate the 2016 drought event. Let's draw a bounding box around cape town and only retrieve reservoir IDs there! Below we first prepare a bounding box in so-called GeoJSON format. This format can be passed to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d0d46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "135d0d46",
    "outputId": "216e9039-5466-4e79-dee0-24a132d54b5f"
   },
   "outputs": [],
   "source": [
    "# first we define a bounding box. We took this from a convenient tool on https://boundingbox.klokantech.com/\n",
    "xmin, ymin, xmax, ymax = (17.948, -34.6538, 19.7361, -33.6857)\n",
    "# we prepare a geometry from the coordinate with shapely.geometry.box\n",
    "bbox = box(xmin, ymin, xmax, ymax)\n",
    "# to pass this to our API, the geometry needs to be serialized to a json, so we first turn it into a dictionary \n",
    "# and then turn it into a string\n",
    "json_dict = mapping(bbox)\n",
    "json_str = json.dumps(json_dict)\n",
    "json_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590df40b",
   "metadata": {
    "id": "590df40b"
   },
   "source": [
    "Et voila! We have a string to pass into our API to retrieve reservoirs over a bounding box. Let's try this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259331cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "id": "259331cf",
    "outputId": "c1ab6b1a-6ba0-4fb3-d553-9ca50ff375cf"
   },
   "outputs": [],
   "source": [
    "# get the reservoirs with a geometry\n",
    "r = get_reservoirs_by_geom(json_str)\n",
    "# convert into geopandas.GeoDataFrame\n",
    "gdf = to_geopandas(r.json())\n",
    "\n",
    "# plot with a more localized GoogleTiles background\n",
    "plot_features_map(gdf, tiles=\"GoogleTiles\", zoom_level=11, tiles_kwargs={\"style\": \"satellite\"}, edgecolor=\"w\", linewidth=2)\n",
    "plt.savefig(\"cape_reservoirs.jpg\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a0a49a",
   "metadata": {
    "id": "d5a0a49a"
   },
   "source": [
    "## Retrieve data for the given reservoirs\n",
    "We now have an interesting list of reservoirs. We can almost start thinking about an analysis. Let us now retrieve the data for the largest reservoir in terms of its polygon area (of course this is time variable if you consider this strictly, the polygon merely gives an approximate outline). Below we retrieve the time series and we'll have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae7d1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "4eae7d1d",
    "outputId": "02ed9198-ef80-4309-b58e-664fb1798bcc"
   },
   "outputs": [],
   "source": [
    "def to_timeseries(data, name=None):\n",
    "    \"\"\"\n",
    "    Convert raw list of jsons to organized pandas.DataFrame\n",
    "    \"\"\"\n",
    "    if name is None:\n",
    "        name = \"area\"\n",
    "\n",
    "    t_index = [p[\"t\"] for p in data]\n",
    "    v = [{name: p[\"value\"]} for p in data]\n",
    "    pd.DatetimeIndex(t_index)\n",
    "    return pd.DataFrame(\n",
    "        v,\n",
    "        index=pd.DatetimeIndex(t_index)\n",
    "    )\n",
    "\n",
    "# first add an area estimate. We do this by projecting to a \"meters\" UTM projection, \n",
    "# ...computing the surface area, adding that as property\n",
    "a = gdf.to_crs(32734).area\n",
    "gdf[\"area\"] = a\n",
    "\n",
    "# now let's find the ID of the largest area reservoir (sort from small to large, last in the list, so index=-1)\n",
    "# first we sort on area\n",
    "gdf = gdf.sort_values(\"area\")\n",
    "\n",
    "# last in the list should be the largest now\n",
    "reservoir_id = gdf.iloc[-1].id\n",
    "s = datetime.datetime(2000, 1, 1)\n",
    "e = datetime.datetime(2020, 12, 31)\n",
    "\n",
    "# retrieve data for the largest reservoir\n",
    "r = get_reservoir_ts(reservoir_id, start=s, stop=e)\n",
    "\n",
    "# again, raw data are not easy to process, so we have a nice function to convert to pandas\n",
    "df = to_timeseries(r.json())\n",
    "ax = plt.subplot(111)\n",
    "df.plot(ax=ax, linewidth=0., marker=\".\")\n",
    "\n",
    "# let's also compute the monthly means so that we can more easily compare against other reservoirs\n",
    "df_mean = df.resample(\"MS\").mean()\n",
    "df_mean.plot(ax=ax, marker=\".\", linewidth=0, label=\"monthly mean\")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ba3b85",
   "metadata": {
    "id": "95ba3b85"
   },
   "source": [
    "Excellent, now we have some data in a form we can work with. We also have monthlies so that we can combine the data with the same time stamps with data from other reservoirs later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10043129",
   "metadata": {
    "id": "10043129"
   },
   "source": [
    "### Data for all reservoirs in bounding box\n",
    "It is clear that we have a logical reservoir pattern and that the period around \"Day Zero\" is very dry. But how does this relate to the surrounding reservoirs? Let's retrieve the data for those and establish monthly anomalies.\n",
    "Below we start with just retrieving the data in the same way as what we did for the one largest reservoir above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a681cb44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "dea6c55aafec47c8a138bdba6f9f9400",
      "09bd59efe8be4a488da881441c233f95",
      "e16dd696f3934f31b4e771e3d7baeda7",
      "f6d9a3f615b049c78f3222b159bd2922",
      "2ca82b7db64d4edb8e08eb29a2e1d716",
      "e3acc1b076b84901b6fffd1e0a2d8c3a",
      "514253ce25164c7fb9192bd40ddbdb93",
      "112f349a06b041419e95accfe72c6e25",
      "89a59e3fd2c243c6a654f6f369086e0c",
      "af1ee13cd72e4bc9b4de580dcc484283",
      "f648912b1f3d461e90648cf45d2915bd"
     ]
    },
    "id": "a681cb44",
    "outputId": "cfa08c05-6753-4888-d475-2ffa421a2ef8"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_per_reservoir = [\n",
    "    to_timeseries(\n",
    "        get_reservoir_ts(gdf[\"id\"][n], start=s, stop=e).json(),\n",
    "        name=\"area_{}\".format(gdf[\"id\"][n]))\n",
    "    for n in tqdm(range(len(gdf)))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f112b45c",
   "metadata": {
    "id": "f112b45c"
   },
   "source": [
    "### Measure the surface area against the climatology\n",
    "For this we use the \"Standardized Area Index\", basically the same as the \"Standardized Precipitation Index\" but then applied on reservoirs. Below all the functionalities are programmed. Please have a look at the detailed docstrings to understand how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7006ecb",
   "metadata": {
    "id": "c7006ecb"
   },
   "outputs": [],
   "source": [
    "def fit(ts, dist='norm', include_zero=False):\n",
    "    \"\"\"\n",
    "    This function fits a distribution (e.g. default gamma, but can be altered to \n",
    "    genextreme, normal, or other supported by scipy.stats) from a number of samples. It can (should) be tested\n",
    "    whether the process fits chosen distribution, e.g. with a goodness of fit or Q-Q plots.\n",
    "    Input:\n",
    "        samples            : the samples from the process, to be described by\n",
    "                             the Gamma distribution\n",
    "        dist:              : chosen distribution, compatible with scipy.stats\n",
    "        include_zero       : Default: True, decide if probability of zero values occurring should be included \n",
    "                             explicitly\n",
    "    Output:\n",
    "        fit_params         : tuple with fit parameters of chosen distribution such as shape, location, scale\n",
    "        prob_zero          : the probability of zero occurring (if relevant)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    samples = ts.values.flatten()  # flatten the matrix to a one-dimensional array\n",
    "    if include_zero:\n",
    "        # compute probability of zero (only relevant for things like rainfall)\n",
    "        prob_zero = float(sum(samples == 0)) / len(samples)\n",
    "    else:\n",
    "        prob_zero = 0.\n",
    "    # find the amount of samples\n",
    "    n = len(samples)\n",
    "    # select the gamma distribution function to work with\n",
    "    dist_func = getattr(stats, dist)\n",
    "    # fit parameters of chosen distribution function, only through non-zero samples\n",
    "    if include_zero:\n",
    "        fit_params = dist_func.fit(samples[(samples != 0) & np.isfinite(samples)])\n",
    "    else:\n",
    "        fit_params = dist_func.fit(samples[np.isfinite(samples)])\n",
    "    # following is returned from the function\n",
    "    return fit_params, prob_zero\n",
    "\n",
    "def quantile_trans(ts, fit_params, p_zero, dist='norm'):\n",
    "    \"\"\"\n",
    "    This function detrermines the normal quantile transform of a number of samples, based on\n",
    "    a known (e.g. Gamma) distribution of the process (can in principle\n",
    "    be extended to support grids instead of point values)\n",
    "    Input:\n",
    "        samples            : the samples from the process, for which standardized index is\n",
    "                             computed\n",
    "        fit_params         : the distribution parameters (need to be of expected size for given distribution)\n",
    "        loc                : the location (mean) parameter of the distribution\n",
    "        beta               : the scale parameter of the distribution\n",
    "        prob_zero          : the probability of zero-rainfall\n",
    "        dist:              : chosen distribution, compatible with scipy.stats\n",
    "    Output:\n",
    "        standardized       : Standardized values of the given samples\n",
    "    \"\"\"\n",
    "    # compute probability of non-exceeding of given sample(s), given the predefined Gamma distribution\n",
    "    samples = ts.values\n",
    "    # find zero samples (only relevant for processes that are zero-bounded such as fluxes, e.g. precipitation)\n",
    "    if p_zero > 0:\n",
    "        ii = samples == 0\n",
    "    # find missings in samples\n",
    "    jj = np.isnan(samples)\n",
    "    # get the requested distribution\n",
    "    dist_func = getattr(stats, dist)\n",
    "    # compute the cumulative distribution function quantile values using the fitted parameters\n",
    "    cdf_samples = dist_func.cdf(samples, *fit_params)\n",
    "    # correct for no rainfall probability\n",
    "    cdf_samples = p_zero + (1 - p_zero) * cdf_samples\n",
    "    if p_zero > 0:\n",
    "        cdf_samples[ii] = p_zero\n",
    "    cdf_samples[jj] = np.nan\n",
    "    # compute inverse normal distribution with mu=0 and sigma=1, this yields the standardized values. \n",
    "    # Basically this means looking up how many standard deviations the given quantile represents in \n",
    "    # a normal distribution with mu=0. and sigma=1.\n",
    "    standardized = stats.norm.ppf(cdf_samples)\n",
    "    return standardized\n",
    "\n",
    "def fit_and_transform(samples, dist='norm', include_zero=True):\n",
    "    # The function below fits the samples to the requested distribution 'norm' or other from scipy.stats\n",
    "    fit_params, p_zero = fit(samples, dist=dist, include_zero=include_zero)\n",
    "    # Then the fitted parameters are used to estimate the standardized samples for each invidual month\n",
    "    standardized_samples = quantile_trans(samples, fit_params, p_zero, dist=dist)\n",
    "    # finally, the standardized samples are put into a pandas timeseries again, so that we can easily make time series plots\n",
    "    # and do further analyses\n",
    "    return pd.Series(standardized_samples, index=samples.index)\n",
    "\n",
    "def compute_standard_index(ts, index='time.month', dist='norm', include_zero=True):\n",
    "    \"\"\"\n",
    "    Compute standardised index. This is done on monthly time series by:\n",
    "    - grouping the monthly data into monthly bins\n",
    "    - for each month fit a distribution function (normal or other from scipy.stats)\n",
    "    - estimate the probability of exceedance of each point in the time series using the 12 distributions\n",
    "    - estimate the normal transform of each probability found using mapping to a standard normal distribution\n",
    "    Input:\n",
    "        ts: pandas Series object containing monthly data (e.g. monthly precipitation, precip-ref. evaporation)\n",
    "        index='time.month': index to use for grouping\n",
    "        dist='norm': distribution to use.\n",
    "    \"\"\"\n",
    "    # first, we group all values per month. So we get a group of January rainfalls, February rainfalls, etc.\n",
    "    ts_group = ts.groupby(index)\n",
    "    # for each group, the SPI values are computed and coerced into a new time series. \n",
    "    standardized_index = ts_group.apply(fit_and_transform, dist=dist, include_zero=include_zero)\n",
    "    return standardized_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb640f",
   "metadata": {
    "id": "95fb640f"
   },
   "source": [
    "### Monthly values\n",
    "Let's perform resampling to monthly values so that we can apply the monthly standardized index functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75dab96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "e75dab96",
    "outputId": "d63fdc9b-355c-4751-93a9-eb135753d618"
   },
   "outputs": [],
   "source": [
    "# resample data for each reservoir to monthly means and concatenate to a new pandas.DataFrame\n",
    "data_monthly = pd.concat([data.resample(\"MS\").mean() for data in data_per_reservoir], axis=1)\n",
    "# plot the last 4 (the largest)\n",
    "data_monthly.iloc[:, -4:].plot(marker=\".\")\n",
    "plt.savefig(\"cape_time_series.jpg\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d6a42",
   "metadata": {
    "id": "5d9d6a42"
   },
   "source": [
    "### Anomalies\n",
    "Now that we have monthly values, we can measure monthly deviations from climatology expressed in standard deviations using the helper functions just loaded. We assume here the the normal distribution fits the sampled monthly values reasonably well, but you can alter that to other distributions if deemed a better fit. Googness of fit testing is here not further shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae54c4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "aae54c4c",
    "outputId": "188153bb-e11d-4562-83ad-5eeead457fd1"
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(13, 7))\n",
    "ax = f.add_subplot(111)\n",
    "index = data_monthly.index.month\n",
    "sai = data_monthly.interpolate().apply(compute_standard_index, index=index, dist=\"norm\")\n",
    "\n",
    "# also make an estimate of the total surface area per month and apply the\n",
    "area_total = data_monthly.interpolate().sum(axis=1)\n",
    "sai_total = compute_standard_index(area_total, index=area_total.index.month, dist=\"norm\")\n",
    "sai_total.plot(marker=\"x\")\n",
    "sai.iloc[:, -4:].plot(ax=ax, marker=\".\", legend=False)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"SAI [-]\")\n",
    "plt.grid()\n",
    "plt.savefig(\"cape_sai.jpg\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644821c9",
   "metadata": {
    "id": "644821c9"
   },
   "source": [
    "### Some scripting for a geospatial video\n",
    "To animate how the situation evolves in time, we can combine our data with a Mapbox background and some `cartopy` and `matplotlib` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b73966",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "14b73966",
    "outputId": "9b55aeb2-5a6b-44ae-8734-45423d2ad933"
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "area = gdf[\"area\"].values\n",
    "utm_geom = gdf.geometry.to_crs(32734)\n",
    "\n",
    "# get the centroid in lat lon coordinates\n",
    "x = utm_geom.centroid.to_crs(4326).x.values\n",
    "y = utm_geom.centroid.to_crs(4326).y.values\n",
    "\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2020-12-01\"\n",
    "\n",
    "dates = pd.date_range(\"2015-01-01\", \"2020-12-01\", freq=\"MS\")\n",
    "\n",
    "datestr1 = dates[0]\n",
    "datestr2 = datestr1 + relativedelta(days=1)\n",
    "\n",
    "osm = cimgt.OSM()\n",
    "f = plt.figure(figsize=(16, 9), frameon=False)\n",
    "ax = plt.subplot(111, projection=osm.crs)\n",
    "\n",
    "# Setting extent with on-the-fly reprojection will work in later versions of python)\n",
    "# uncomment below in case you are running this in your own python env. to get a\n",
    "# more close matching bounding box for the available data.\n",
    "# ============================================================================= \n",
    "# ax.set_extent([18, 20, -34.7, -33.5], crs=ccrs.PlateCarree())\n",
    "# ============================================================================= \n",
    "\n",
    "ax.add_image(osm, 9, interpolation='bilinear')\n",
    "bounds = np.linspace(-3., 3., 9)\n",
    "norm = matplotlib.colors.BoundaryNorm(boundaries=bounds, ncolors=256)\n",
    "p = ax.scatter(\n",
    "    x,\n",
    "    y,\n",
    "    s=area/2e4,\n",
    "    c=sai[datestr1:datestr2].values.flatten(),\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    alpha=0.8,\n",
    "    cmap=\"RdYlBu\",\n",
    "    norm=norm,\n",
    "    edgecolor=\"#555555\",\n",
    "    linewidth=2,\n",
    ")\n",
    "# Gridlines with on-the-fly reprojection will work in later versions of python)\n",
    "# uncomment below in case you are running this in your own python env.\n",
    "# ============================================================================= \n",
    "# gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "#                   linewidth=1, color='gray', alpha=0., linestyle='--')\n",
    "# gl.top_labels = False\n",
    "# gl.left_labels = False\n",
    "# gl.xformatter = LONGITUDE_FORMATTER\n",
    "# gl.yformatter = LATITUDE_FORMATTER\n",
    "# ============================================================================= \n",
    "\n",
    "cb = plt.colorbar(p, extend=\"both\")\n",
    "cb.set_label(\"Standardised Area Index [-]\")\n",
    "title = plt.title(f\"Standardized Area Index {datestr1}\")\n",
    "\n",
    "# # add time series inset\n",
    "ax_inset = ax.inset_axes([0.6, 0.05, 0.38, 0.15])\n",
    "\n",
    "# plot a time slider\n",
    "m1 = ax_inset.plot(dates[0], sai_total[sai_total.index==dates[0]], label=\"Southern Africa\", marker=\".\", color='red', markersize=20)\n",
    "sai_total[start_date:end_date].plot(ax=ax_inset, label=\"Southern Africa\", color=\"red\")\n",
    "i = sai_total[start_date:end_date].index\n",
    "pd.DataFrame({\"zero_ax\": np.zeros(len(i))}, index=i).plot(color=\"#888888\", linewidth=0.6, ax=ax_inset, legend=False)\n",
    "\n",
    "# lay out of the inset plot with SAI for all reservoirs together\n",
    "ax_inset.set_ylabel(\"Standardize Area Index [-]\")\n",
    "ax_inset.set_xlabel(\"\")\n",
    "ax_inset.set_ylabel(\"\")\n",
    "ax_inset.patch.set_alpha(0.6)\n",
    "ax_inset.set_ylim([-4, 4])\n",
    "ax_inset.spines['top'].set_visible(False)\n",
    "ax_inset.spines['right'].set_visible(False)\n",
    "ax_inset.spines['bottom'].set_visible(False)\n",
    "ax_inset.spines['left'].set_visible(False)\n",
    "ax_inset.tick_params(axis='both', colors='black')\n",
    "\n",
    "\n",
    "ax_inset.tick_params(axis='x', labelsize=8)\n",
    "tick_locs = np.arange(2014, 2022)\n",
    "ticks = ax_inset.xaxis.set_major_locator(matplotlib.ticker.FixedLocator(tick_locs))\n",
    "ticklabels = ax_inset.set_xticklabels([str(tick) for tick in tick_locs], rotation = 0)\n",
    "\n",
    "def update_plot(i):\n",
    "    datestr1 = dates[i]\n",
    "    datestr2 = datestr1 + relativedelta(days=1)\n",
    "    p.set_array(sai[datestr1:datestr2].values.flatten())\n",
    "    m1[0].set_xdata(dates[i])\n",
    "    m1[0].set_ydata(sai_total[dates[i]])\n",
    "    ax.set_title(f\"Standardized Area Index {datestr1}\")\n",
    "\n",
    "matplotlib.rcParams['animation.embed_limit'] = 1e9\n",
    "ani = animation.FuncAnimation(f, update_plot, frames=tqdm(range(len(dates))), interval=500)\n",
    "plt.close()\n",
    "\n",
    "# uncomment the line below to store the movie in a file instead of a on-the-fly HTML video\n",
    "# ============================================================================= \n",
    "# ani.save(\"sai_southern_africa.mp4\", fps=2, dpi=200)\n",
    "# ============================================================================= \n",
    "# comment the line below to not show the video here in line\n",
    "# ============================================================================= \n",
    "HTML(ani.to_jshtml())\n",
    "# ============================================================================= \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a48b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09bd59efe8be4a488da881441c233f95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3acc1b076b84901b6fffd1e0a2d8c3a",
      "placeholder": "​",
      "style": "IPY_MODEL_514253ce25164c7fb9192bd40ddbdb93",
      "value": "100%"
     }
    },
    "112f349a06b041419e95accfe72c6e25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ca82b7db64d4edb8e08eb29a2e1d716": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "514253ce25164c7fb9192bd40ddbdb93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89a59e3fd2c243c6a654f6f369086e0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "af1ee13cd72e4bc9b4de580dcc484283": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dea6c55aafec47c8a138bdba6f9f9400": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_09bd59efe8be4a488da881441c233f95",
       "IPY_MODEL_e16dd696f3934f31b4e771e3d7baeda7",
       "IPY_MODEL_f6d9a3f615b049c78f3222b159bd2922"
      ],
      "layout": "IPY_MODEL_2ca82b7db64d4edb8e08eb29a2e1d716"
     }
    },
    "e16dd696f3934f31b4e771e3d7baeda7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_112f349a06b041419e95accfe72c6e25",
      "max": 61,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89a59e3fd2c243c6a654f6f369086e0c",
      "value": 61
     }
    },
    "e3acc1b076b84901b6fffd1e0a2d8c3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f648912b1f3d461e90648cf45d2915bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6d9a3f615b049c78f3222b159bd2922": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af1ee13cd72e4bc9b4de580dcc484283",
      "placeholder": "​",
      "style": "IPY_MODEL_f648912b1f3d461e90648cf45d2915bd",
      "value": " 61/61 [00:29&lt;00:00,  2.13it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
